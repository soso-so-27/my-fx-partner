import { NextRequest, NextResponse } from 'next/server'
import OpenAI from 'openai'

const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
})

const IMAGE_ANALYSIS_PROMPT = `ã‚ãªãŸã¯FXãƒãƒ£ãƒ¼ãƒˆã‚’åˆ†æã™ã‚‹ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚

ã€åˆ†æã®è¦³ç‚¹ã€‘
1. ãƒãƒ£ãƒ¼ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒ€ãƒ–ãƒ«ãƒˆãƒƒãƒ—ã€ä¸‰è§’ä¿ã¡åˆã„ç­‰ï¼‰
2. ãƒˆãƒ¬ãƒ³ãƒ‰ã®æ–¹å‘æ€§
3. ã‚µãƒãƒ¼ãƒˆ/ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹ãƒ©ã‚¤ãƒ³
4. ãƒ­ãƒ¼ã‚½ã‚¯è¶³ã®ãƒ‘ã‚¿ãƒ¼ãƒ³

ã€é‡è¦ãªåˆ¶ç´„ã€‘
- æŠ•è³‡åŠ©è¨€ã¯çµ¶å¯¾ã«ã—ãªã„
- ã€Œè²·ã†ã¹ãã€ã€Œå£²ã‚‹ã¹ãã€ãªã©ã®æ¨å¥¨ã¯ã—ãªã„
- å®¢è¦³çš„ãªè¦³å¯Ÿäº‹å®Ÿã®ã¿ã‚’ä¼ãˆã‚‹
- æœ€çµ‚åˆ¤æ–­ã¯ãƒˆãƒ¬ãƒ¼ãƒ€ãƒ¼è‡ªèº«ãŒè¡Œã†ã“ã¨ã‚’æ˜è¨˜

ã€å‡ºåŠ›å½¢å¼ã€‘
1. ğŸ“ˆ è¦³å¯Ÿã§ãã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³
2. ğŸ“Š ãƒˆãƒ¬ãƒ³ãƒ‰çŠ¶æ³
3. ğŸ” æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ
4. â“ ãƒˆãƒ¬ãƒ¼ãƒ€ãƒ¼ã¸ã®è³ªå•ï¼ˆè‡ªåˆ†ã§è€ƒãˆã•ã›ã‚‹ï¼‰

ã€Œã“ã®åˆ†æã¯å‚è€ƒæƒ…å ±ã§ã‚ã‚Šã€æŠ•è³‡åˆ¤æ–­ã¯ã”è‡ªèº«ã®è²¬ä»»ã§è¡Œã£ã¦ãã ã•ã„ã€ã¨ã„ã†å…è²¬ã‚’æœ€å¾Œã«å¿…ãšå…¥ã‚Œã¦ãã ã•ã„ã€‚`

export async function POST(request: NextRequest) {
    try {
        const { imageBase64, imageUrl, context = '' } = await request.json()

        if (!imageBase64 && !imageUrl) {
            return NextResponse.json({ error: 'Image data is required' }, { status: 400 })
        }

        const imageContent: OpenAI.ChatCompletionContentPart = imageUrl
            ? { type: 'image_url', image_url: { url: imageUrl } }
            : { type: 'image_url', image_url: { url: `data:image/jpeg;base64,${imageBase64}` } }

        const completion = await openai.chat.completions.create({
            model: 'gpt-4o', // Vision capabilities require gpt-4o
            messages: [
                { role: 'system', content: IMAGE_ANALYSIS_PROMPT },
                {
                    role: 'user',
                    content: [
                        imageContent,
                        {
                            type: 'text',
                            text: context
                                ? `ã“ã®ãƒãƒ£ãƒ¼ãƒˆç”»åƒã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚\n\nã€è¿½åŠ æƒ…å ±ã€‘${context}`
                                : 'ã“ã®ãƒãƒ£ãƒ¼ãƒˆç”»åƒã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚'
                        }
                    ]
                }
            ],
            max_tokens: 1000,
            temperature: 0.5,
        })

        const analysis = completion.choices[0]?.message?.content || 'ç”»åƒåˆ†æã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚'

        return NextResponse.json({
            analysis,
            usage: completion.usage,
        })
    } catch (error) {
        console.error('Image analysis error:', error)

        if (error instanceof OpenAI.APIError && error.status === 400) {
            return NextResponse.json({
                error: 'Invalid image format',
                analysis: 'ç”»åƒå½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚JPEGã¾ãŸã¯PNGå½¢å¼ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚'
            }, { status: 400 })
        }

        return NextResponse.json({
            error: 'Failed to analyze image',
            analysis: 'ç”»åƒåˆ†æã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸã€‚'
        }, { status: 500 })
    }
}
